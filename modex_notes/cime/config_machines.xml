<?xml version="1.0"?>
<config_machines version="2.0">
   <machine MACH="modex">
      <DESC>Medium sized linux cluster at BNL</DESC>
      <OS>LINUX</OS>
      <COMPILERS>gnu</COMPILERS>
      <MPILIBS>openmpi,mpi-serial</MPILIBS>
      <PROJECT>modex_simulations</PROJECT>
      <CIME_OUTPUT_ROOT>/output</CIME_OUTPUT_ROOT>
      <DIN_LOC_ROOT>/inputdata</DIN_LOC_ROOT>
      <DIN_LOC_ROOT_CLMFORC>/inputdata/atm/datm7</DIN_LOC_ROOT_CLMFORC>
      <DOUT_S_ROOT>$CIME_OUTPUT_ROOT/archive/$CASE</DOUT_S_ROOT>
      <BASELINE_ROOT>/baselines</BASELINE_ROOT>
      <CCSM_CPRNC>/tools/cprnc</CCSM_CPRNC>
      <!--<GMAKE>make</GMAKE>-->
      <GMAKE_J>8</GMAKE_J>
      <BATCH_SYSTEM>none</BATCH_SYSTEM>
      <!--<BATCH_SYSTEM>slurm</BATCH_SYSTEM>-->
      <SUPPORTED_BY>sserbin at bnl dot gov</SUPPORTED_BY>
      <MAX_TASKS_PER_NODE>24</MAX_TASKS_PER_NODE>
      <MAX_MPITASKS_PER_NODE>24</MAX_MPITASKS_PER_NODE>
      <PROJECT_REQUIRED>FALSE</PROJECT_REQUIRED>
      <mpirun mpilib="mpi-serial">
	      <executable>mpirun</executable>
	      <arguments>
	      	    <arg name="num_tasks">-np $TOTALPES</arg>
                    <arg name="tasks_per_node"> -npernode $MAX_TASKS_PER_NODE</arg>
	      </arguments>
      </mpirun>
      <!--<mpirun mpilib="default">-->
      <mpirun mpilib="openmpi">
	      <executable>mpirun</executable>
	      <arguments>
	            <arg name="num_tasks"> -np $TOTALPES</arg>
	            <arg name="tasks_per_node"> -npernode $MAX_TASKS_PER_NODE</arg>
	      </arguments>
      </mpirun>
      <module_system type="module">
	  <init_path lang="sh">/etc/profile.d/modules.sh</init_path>
          <init_path lang="csh">/etc/profile.d/modules.csh</init_path>
          <init_path lang="perl">/usr/share/Modules/init/perl.pm</init_path>
          <init_path lang="python">/usr/share/Modules/init/python.py</init_path>
          <cmd_path lang="sh">module</cmd_path>
          <cmd_path lang="csh">module</cmd_path>
          <cmd_path lang="perl">/usr/bin/modulecmd perl</cmd_path>
	  <cmd_path lang="python">/usr/bin/modulecmd python</cmd_path>
	  <modules>
	      <command name="load">python/2.7.18-gcc840</command>
	      <command name="load">python/3.9.11-gcc850</command>
          </modules>
          <modules compiler="gnu" mpilib="mpi-serial">
	      <!--<command name="load">openmpi/4.1.2-gcc850</command>-->
	      <!--<command name="load">openmpi/4.1.4-gcc850</command>
	      <command name="load">hdf5/1.12.1-gcc850-ompi412</command>
	      <command name="load">PnetCDF/1.12.3-gcc850-ompi412</command>
	      <command name="load">netcdf/4.8.1-gcc850-ompi412</command>-->
	      <command name="load">hdf5/1.12.1-gcc850</command>
	      <command name="load">netcdf/4.8.1-gcc850</command>
	      <command name="load">openmpi/4.1.4-gcc850</command>
	  </modules>
          <modules compiler="gnu" mpilib="!mpi-serial">
		  <!--<command name="load">openmpi/4.1.2-gcc850</command>-->
		  <command name="load">openmpi/4.1.4-gcc850</command>
		  <command name="load">hdf5/1.12.1-gcc850-ompi412</command>
		  <command name="load">PnetCDF/1.12.3-gcc850-ompi412</command>
		  <command name="load">netcdf/4.8.1-gcc850-ompi412</command>
          </modules>
      </module_system>
      <environment_variables>
	<!--<env name="HDF5_HOME">/data/software/hdf5/1.12.1-gcc850-ompi412</env>
	<env name="NETCDF_PATH">/data/software/netcdf/4.8.1-gcc850-ompi412</env>
        <env name="NETCDF_C_PATH">/data/software/netcdf/4.8.1-gcc850-ompi412</env>
	<env name="NETCDF_FORTRAN_PATH">/data/software/netcdf/4.8.1-gcc850-ompi412</env>-->
	<env name="HDF5_HOME">$SHELL{dirname $(dirname $(which h5diff))}</env>
	<env name="NETCDF_PATH">$SHELL{nc-config --prefix}</env>
	<env name="NETCDF_C_PATH">$SHELL{nc-config --prefix}</env>
	<env name="NETCDF_FORTRAN_PATH">$SHELL{nc-config --prefix}</env>
     </environment_variables>
   </machine>
</config_machines>
